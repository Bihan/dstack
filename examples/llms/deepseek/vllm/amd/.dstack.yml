type: service
name: deepseek-r1-amd

image: rocm/vllm:rocm6.2_mi300_ubuntu20.04_py3.9_vllm_0.6.4
env:
  - MODEL_ID=deepseek-ai/DeepSeek-R1-Distill-Llama-70B
  - MAX_MODEL_LEN=4096

commands:
  - pip install vllm
  - vllm serve $MODEL_ID
    --max-model-len $MAX_MODEL_LEN

port: 8000

model:
  name: deepseek-ai/DeepSeek-R1-Distill-Llama-70B
  type: chat
  format: openai


resources:
    gpu: mi300x
    disk: 300Gb
