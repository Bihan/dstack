type: service
name: deepseek-r1-nvidia

image: vllm/vllm-openai:latest
env:
  - MODEL_ID=deepseek-ai/DeepSeek-R1-Distill-Llama-8B
  - MAX_MODEL_LEN=4096
commands:
  - pip install vllm
  - vllm serve $MODEL_ID
    --max-model-len $MAX_MODEL_LEN

port: 8000

model:
  name: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
  type: chat
  format: openai

resources:
    gpu: 24GB
