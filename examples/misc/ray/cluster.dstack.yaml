type: task
name: ray-cluster
nodes: 2
image: rocm/vllm:rocm6.2_mi300_ubuntu20.04_py3.9_vllm_0.6.4

env:
NCCL_DEBUG=TRACE
GPU_MAX_HW_QUEUES=2
TORCH_NCCL_HIGH_PRIORITY=1
NCCL_CHECKS_DISABLE=1
NCCL_IB_HCA=mlx5_0/1,bnxt_re0,bnxt_re1,bnxt_re2,bnxt_re3,bnxt_re4,bnxt_re5,bnxt_re6,bnxt_re7
NCCL_IB_GID_INDEX=3
NCCL_CROSS_NIC=0
CUDA_DEVICE_MAX_CONNECTIONS=1
NCCL_PROTO=Simple
RCCL_MSCCL_ENABLE=0
TOKENIZERS_PARALLELISM=false
HSA_NO_SCRATCH_RECLAIM=1
HIP_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ROCR_VISIBLE_DEVICES=$HIP_VISIBLE_DEVICES
CUDA_VISIBLE_DEVICES=$HIP_VISIBLE_DEVICES
#NCCL_SOCKET_IFNAME=ens41np0
#export GLOO_SOCKET_IFNAME=ens41np0 

commands:
  - pip install -U "ray[default]"
  # Need to clean image
  - apt remove rdma-core -y
  - rm -rf /opt/ompi
  - rm /usr/bin/mpirun
  # Need to test whether required in both nodes:
  - git clone https://github.com/volcengine/verl.git
  - cd verl
  - wget ... requirementsfor rocm
  - pip install -r requirements_rcom.txt
  - pip install -e . --no-deps # Verl Installation
  - python3 examples/data_preprocess/gsm8k.py --local_dir ../data/gsm8k # data preparation
  # model download
  - python3 -c "import transformers;transformers.pipeline('text-generation', model='Qwen/Qwen2-7B-Instruct')"
  - python3 -c "import transformers;transformers.pipeline('text-generation', model='deepseek-ai/deepseek-llm-7b-chat')"
  - >
    if [ $DSTACK_NODE_RANK = 0 ]; then 
      ray start --head --port=6379;
    else
      ray start --address=$DSTACK_MASTER_NODE_IP:6379
    fi
ports:
  - 8265 # ray dashboard port
resources:
  gpu: mi300x:8
  shm_size: 64GB


cp -Lr /usr/lib/x86_64-linux-gnu/libibverbs /tmp/libibverbs_resolved
docker cp /tmp/libibverbs_resolved/. 24e70f4e0a19:/usr/lib/x86_64-linux-gnu/libibverbs
